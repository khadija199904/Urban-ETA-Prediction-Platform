Voici une version compl√®te, professionnelle et ultra-d√©taill√©e de votre fichier **README.md**. Elle est structur√©e pour mettre en valeur la complexit√© technique de votre projet (ETL distribu√© + ML + API s√©curis√©e).

---

# üöÄ Smart LogiTrack : Urban ETA Prediction Platform

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Apache Airflow](https://img.shields.io/badge/Apache_Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white)](https://airflow.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit_Learn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)](https://scikit-learn.org/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)

**Smart LogiTrack** est une plateforme de "Control Tower" logistique permettant de pr√©dire le Temps d'Arriv√©e Estim√© (ETA) des taxis urbains. Ce projet impl√©mente un pipeline complet : de l'ingestion massive de donn√©es (Bronze) au nettoyage distribu√© (Silver), jusqu'au d√©ploiement d'une API de pr√©diction haute performance.

---

##  Architecture du Syst√®me

Le projet est construit sur une architecture  :
1.  **Ingestion (Bronze)** : R√©cup√©ration automatique du dataset Taxi via Airflow.
2.  **Transformation (Silver)** : Nettoyage et Feature Engineering avec **PySpark** pour une scalabilit√© maximale.
3.  **Machine Learning** : Entra√Ænement et comparaison de mod√®les (Spark ML vs Scikit-Learn).
4.  **Service (API)** : API REST (FASTAPI) s√©curis√©e par JWT offrant des pr√©dictions et des analyses analytiques.
5.  **Orchestration** : Gestion des t√¢ches via Apache Airflow.

---

##  Structure du Projet

```text
‚îú‚îÄ‚îÄ api/                # Application Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ core/           # Config (DB, JWT), S√©curit√© (hashing, verify-token)
‚îÇ   ‚îú‚îÄ‚îÄ routers/        # Endpoints (Predict, Analytics, Auth)
‚îÇ   ‚îú‚îÄ‚îÄ crud/           # Logique d'acc√®s aux donn√©es (user.py)
‚îÇ   ‚îú‚îÄ‚îÄ models/         # Mod√®les SQLAlchemy (history_predictions.py, users.py)
‚îÇ   ‚îú‚îÄ‚îÄ outils/         # Utilitaires (execute_query, load_model, log_predictions)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/        # Validation Pydantic (predict_schema, users_schema)
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Logique m√©tier (prediction.py)
‚îÇ   ‚îú‚îÄ‚îÄ database.py     # Connexion Base de Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ dependeces.py   # Injection de d√©pendances (get_db)
‚îÇ   ‚îî‚îÄ‚îÄ main.py         # Point d'entr√©e API
‚îú‚îÄ‚îÄ dags/               # Pipelines d'orchestration Apache Airflow
‚îú‚îÄ‚îÄ ML/                 # Scripts d'entra√Ænement et recherche de mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ models_pkl/         # Mod√®les ML s√©rialis√©s (.pkl)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/          # Exploration de donn√©es & prototypes Spark
‚îÇ   ‚îî‚îÄ‚îÄ Scripts/            # Fonctions utilitaires pour les DAGs Airflow
‚îú‚îÄ‚îÄ Tests/              # Tests unitaires et d'int√©gration (Pytest)
‚îú‚îÄ‚îÄ data/               # Stockage local des donn√©es (Bronze/Silver)
‚îú‚îÄ‚îÄ docker-compose.yml  # Orchestration des conteneurs
‚îú‚îÄ‚îÄ Dockerfile          # Configuration de l'image Docker API
‚îú‚îÄ‚îÄ .gitignore          # Fichiers √† exclure de Git
‚îú‚îÄ‚îÄ .dockerignore       # Fichiers √† exclure de l'image Docker
‚îú‚îÄ‚îÄ init_airflow.sh     # Script d'initialisation Airflow
‚îî‚îÄ‚îÄ requirements.txt    # D√©pendances Python
```

---

##  Performance du Machine Learning

Nous avons men√© une √©tude comparative entre deux approches pour pr√©dire la dur√©e du trajet (`trip_duree`) :

| Framework | Mod√®le | R¬≤ | RMSE |
| :--- | :--- | :--- | :--- |
| **Scikit-Learn** | **Random Forest Regressor** | **0.96** | **1.40** |
| Apache Spark | GBTRegressor | 0.93 | 1.88 |

> **Le mod√®le Random Forest (Sklearn)** a √©t√© choisi pour la production car il offre la meilleure pr√©cision et une latence de pr√©diction plus faible pour l'API.

---

##  Fonctionnalit√©s de l'API

L'API est s√©curis√©e par **JWT (JSON Web Tokens)** et propose les services suivants :

*   **Auth** : Inscription (`/register`) et Connexion (`/login`).
*   **Predictions** : 
    *   `POST /predict` : Re√ßoit les caract√©ristiques du trajet et renvoie la dur√©e estim√©e.
    *   Historisation automatique de chaque requ√™te dans la table `history_predictions`.
*   **Analytics** :
    *   `GET /analytics/avg-duration-by-hour` : Dur√©e moyenne des trajets par heure.
    *   `GET /analytics/payment-analysis` : Analyse de la dur√©e moyenne selon le type de paiement.

---

##  Installation et D√©marrage

### 1. Pr√©requis
*   Windows avec **WSL2** ou Linux.
*   **Docker** & **Docker Compose**.

### 2. Installation locale
```bash
# Cloner le projet
git clone https://github.com/khadija199904/Urban-ETA-Prediction-Platform.git
cd Urban-ETA-Prediction-Platform

# Cr√©er un environnement virtuel
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Lancement des services
```bash
# Lancer Postgres, Airflow et l'API en arri√®re-plan
docker-compose up -d
```

### 4. Tests
Pour ex√©cuter la suite de tests unitaires (avec mocks pour la DB et le Token) :
```bash
pytest
```

---

## Stack Technologique
*   **Backend** : FastAPI, SQLAlchemy, Pydantic, JWT.
*   **Big Data** : Apache Spark (PySpark), Apache Airflow.
*   **Machine Learning** : Scikit-Learn (Random Forest), Spark MLlib.
*   **DevOps** : Docker, Docker Compose, WSL2.
*   **Base de donn√©es** : PostgreSQL.

---

##  Auteur
**Khadija**
*   [GitHub](https://github.com/khadija199904)
*   [Projet Repository](https://github.com/khadija199904/Urban-ETA-Prediction-Platform)

*Ce projet a √©t√© r√©alis√© dans le cadre de la certification D√©veloppeur en Intelligence Artificielle.*